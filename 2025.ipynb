from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, upper

# Initialize Spark session
spark = SparkSession.builder \
    .appName("Data Cleaning Example") \
    .getOrCreate()

# Read data
df = spark.read.csv("sample_data/people.csv", header=True, inferSchema=True)

# Show original data
print("Original Data:")
df.show()

# Clean data: uppercase names, fill null age, flag minors
cleaned_df = df.withColumn("name", upper(col("name"))) \
               .withColumn("age", when(col("age").isNull(), 0).otherwise(col("age"))) \
               .withColumn("is_minor", when(col("age") < 18, True).otherwise(False))

print("Cleaned Data:")
cleaned_df.show()

# Stop Spark session
spark.stop()
